{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4441533-4d5a-4c9e-8906-1df24bda96ec",
   "metadata": {},
   "source": [
    "## Tutorial 1. VGG7 on CIFAR10. \n",
    "\n",
    "\n",
    "In this tutorial, we will show \n",
    "\n",
    "- How to end-to-end train and compress a VGG7 model from scratch on CIFAR10 to get a pruned and quantized VGG7.\n",
    "- We apply both weight and activation quantization when training VGG7 model.\n",
    "- Using the following script, we are able to reach a 92.57% test accuracy with 0.41% relative bits of operation.\n",
    "<!-- - The compressed ResNet18 achives both **high performance** and **significant FLOPs and parameters reductions** than the full model. \n",
    "- The compressed ResNet18 **reduces about 92% parameters** to achieve **92.91% accuracy** only lower than the baseline by **0.11%**.\n",
    "- More detailed new HESSO optimizer setup. (Technical report regarding HESSO will be released on the early of 2024). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067c3a6-bf56-4c85-96fb-2d4da488680b",
   "metadata": {},
   "source": [
    "### Step 1. Create OTO instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0399-51c7-4afc-b0f0-35bda3698825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from only_train_once.quantization.quant_model import model_to_quantize_model\n",
    "from only_train_once.quantization.quant_layers import QuantizationMode\n",
    "from sanity_check.backends.vgg7 import vgg7_bn\n",
    "from only_train_once import OTO\n",
    "import torch\n",
    "\n",
    "model = vgg7_bn()\n",
    "model = model_to_quantize_model(model, quant_mode=QuantizationMode.WEIGHT_AND_ACTIVATION)\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "oto = OTO(model=model.cuda(), dummy_input=dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01639056-422d-4bfb-89db-ff9f0725e807",
   "metadata": {},
   "source": [
    "#### (Optional) Visualize the pruning dependancy graph of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cefb1-85cf-4833-a6ff-ee2f9270f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ResNet_zig.gv.pdf will be generated to display the depandancy graph.\n",
    "oto.visualize(view=False, out_dir='../cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99fc48-fed7-41a5-ab6d-f2e5686f2003",
   "metadata": {},
   "source": [
    "### Step 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec145d-4847-4f4b-8c12-782beb61cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trainset = CIFAR10(root='cifar10', train=True, download=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "testset = CIFAR10(root='cifar10', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65233349-da36-47bc-9af8-41a3f2d4429a",
   "metadata": {},
   "source": [
    "### Step 3. Setup the optimizer\n",
    "\n",
    "The following main hyperparameters need to be taken care.\n",
    "\n",
    "- `variant`: The optimizer that is used for training the baseline full model. Currently support `sgd`, `adam` and `adamw`.\n",
    "- `lr`: The initial learning rate.\n",
    "- `weight_decay`: Weight decay as standard DNN optimization.\n",
    "- `target_group_sparsity`: The target group sparsity, typically higher group sparsity refers to more FLOPs and model size reduction, meanwhile may regress model performance more.\n",
    "- `start_projection_step`: The number of steps that **starts** to do bit width projection.\n",
    "- `projection_steps`: The number of steps that **finishes** bit width projection (reach target bit width) after `start_projection_steps`.\n",
    "- `projection_periods`: Incrementally produce the group sparsity equally among projection periods.\n",
    "- `start_pruning_step`: The number of steps that **starts** to prune.\n",
    "- `pruning_steps`: The number of steps that **finishes** pruning (reach `target_group_sparsity`) after `start_pruning_steps`.\n",
    "- `pruning_periods`:  Incrementally produce the group sparsity equally among pruning periods.\n",
    "- `bit reduction`: the reduction of `max_bit` after the end of each projection period.\n",
    "- [`min_bit`,`max_bit`]: Initial bit width interval. The `max_bit` will reduce by `bit_reduction` after each projection period.\n",
    "\n",
    "<!-- We empirically suggest `start_pruning_steps` as 1/10 of total number of training steps. `pruning_steps` until 1/4 or 1/5 of total number of training steps.\n",
    "The advatnages of HESSO compared to DHSPG is its explicit control over group sparsity exploration, which is typically more convenient. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af4116-bb7e-4156-bc3d-c32c8fc6f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = oto.geta(\n",
    "    variant=\"adam\",\n",
    "    lr=1e-3,\n",
    "    lr_quant=1e-3,\n",
    "    first_momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    "    target_group_sparsity=0.5,\n",
    "    start_projection_step=0 * len(trainloader),\n",
    "    projection_periods=5,\n",
    "    projection_steps=10 * len(trainloader),\n",
    "    start_pruning_step=10 * len(trainloader),\n",
    "    pruning_periods=5,\n",
    "    pruning_steps=10 * len(trainloader),\n",
    "    bit_reduction=2,\n",
    "    min_bit_wt=4,\n",
    "    max_bit_wt=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632cb7e-e1ae-460c-b415-81c158c80a20",
   "metadata": {},
   "source": [
    "### Step 4. Train VGG7 as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d98a1-a77b-4cc6-9acd-a1483c17e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorials.utils.utils import check_accuracy\n",
    "\n",
    "max_epoch = 50\n",
    "model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Every 50 epochs, decay lr by 10.0\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) \n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    f_avg_val = 0.0\n",
    "    model.train()\n",
    "    lr_scheduler.step()\n",
    "    for X, y in trainloader:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model.forward(X)\n",
    "        f = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        f.backward()\n",
    "        f_avg_val += f\n",
    "        optimizer.step()\n",
    "    opt_metrics = optimizer.compute_metrics()\n",
    "    accuracy1, accuracy5 = check_accuracy(model, testloader)\n",
    "    f_avg_val = f_avg_val.cpu().item() / len(trainloader)\n",
    "    \n",
    "    print(\"Ep: {ep}, loss: {f:.2f}, norm_all:{param_norm:.2f}, grp_sparsity: {gs:.2f}, acc1: {acc1:.4f}, norm_import: {norm_import:.2f}, norm_redund: {norm_redund:.2f}, num_grp_import: {num_grps_import}, num_grp_redund: {num_grps_redund}\"\\\n",
    "         .format(ep=epoch, f=f_avg_val, param_norm=opt_metrics.norm_params, gs=opt_metrics.group_sparsity, acc1=accuracy1,\\\n",
    "         norm_import=opt_metrics.norm_important_groups, norm_redund=opt_metrics.norm_redundant_groups, \\\n",
    "         num_grps_import=opt_metrics.num_important_groups, num_grps_redund=opt_metrics.num_redundant_groups\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8dabf9-04cf-4d55-89e4-a17c96d17cec",
   "metadata": {},
   "source": [
    "### Step 5. Get compressed model in torch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e6b6e-6286-4f57-816f-f94f6ce5c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default OTO will construct subnet by the last checkpoint. If intermedia ckpt reaches the best performance,\n",
    "# need to reinitialize OTO instance\n",
    "# oto = OTO(torch.load(ckpt_path), dummy_input)\n",
    "# then construct subnetwork\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "oto.construct_subnet(out_dir='./cache')\n",
    "compressed_model = torch.load(oto.compressed_model_path)\n",
    "oto_compressed = OTO(compressed_model, dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cd3b6-1db9-473d-9585-27e08c669265",
   "metadata": {},
   "source": [
    "### (Optional) Check the compressed model size\n",
    "- MACs: Multiply and accumulations\n",
    "- BOPs: Bit of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc731c99-3155-472e-9462-65ed8c9bf4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get full model MACs, BOPs\n",
    "full_macs = oto.compute_macs(in_million=True, layerwise=True)\n",
    "full_bops = oto.compute_bops(in_million=True, layerwise=True)\n",
    "full_num_params = oto.compute_num_params(in_million=True)\n",
    "\n",
    "# Get compressed model MACs, BOPs\n",
    "compressed_macs = oto_compressed.compute_macs(in_million=True, layerwise=True)\n",
    "compressed_bops = oto_compressed.compute_bops(in_million=True, layerwise=True)\n",
    "\n",
    "print(f\"Full MACs for VGG7: {full_macs['total']} M MACs\")\n",
    "print(f\"Full BOPs for VGG7: {full_bops['total']} M BOPs\")\n",
    "print(f\"Compressed MACs for VGG7: {compressed_macs['total']} M MACs\")\n",
    "print(f\"Compressed BOPs for VGG7: {compressed_bops['total']} M BOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qhesso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
