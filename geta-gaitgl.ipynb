{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Set up environment","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\n\ndef set_seed(seed=42):\n    \"\"\"Set seed for reproducibility\"\"\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    print(f\"Seed set to {seed} for future runs\")\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:59:01.768351Z","iopub.execute_input":"2025-09-28T13:59:01.768623Z","iopub.status.idle":"2025-09-28T13:59:01.776126Z","shell.execute_reply.started":"2025-09-28T13:59:01.768596Z","shell.execute_reply":"2025-09-28T13:59:01.775441Z"}},"outputs":[{"name":"stdout","text":"Seed set to 42 for future runs\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"cd \"/kaggle/working/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:51:42.060134Z","iopub.execute_input":"2025-09-28T13:51:42.060372Z","iopub.status.idle":"2025-09-28T13:51:42.065414Z","shell.execute_reply.started":"2025-09-28T13:51:42.060355Z","shell.execute_reply":"2025-09-28T13:51:42.064771Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\n!pwd\n!git clone https://github.com/ShiqiYu/OpenGait.git\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:52:07.392256Z","iopub.execute_input":"2025-09-28T13:52:07.392530Z","iopub.status.idle":"2025-09-28T13:52:09.201011Z","shell.execute_reply.started":"2025-09-28T13:52:07.392507Z","shell.execute_reply":"2025-09-28T13:52:09.200091Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'OpenGait'...\nremote: Enumerating objects: 2100, done.\u001b[K\nremote: Counting objects: 100% (804/804), done.\u001b[K\nremote: Compressing objects: 100% (290/290), done.\u001b[K\nremote: Total 2100 (delta 675), reused 514 (delta 514), pack-reused 1296 (from 6)\u001b[K\nReceiving objects: 100% (2100/2100), 20.36 MiB | 35.33 MiB/s, done.\nResolving deltas: 100% (1294/1294), done.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/OpenGait/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:59:14.014625Z","iopub.execute_input":"2025-09-28T13:59:14.014904Z","iopub.status.idle":"2025-09-28T13:59:14.018541Z","shell.execute_reply.started":"2025-09-28T13:59:14.014885Z","shell.execute_reply":"2025-09-28T13:59:14.017760Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:14:48.251166Z","iopub.execute_input":"2025-09-07T06:14:48.251866Z","iopub.status.idle":"2025-09-07T06:14:52.237762Z","shell.execute_reply.started":"2025-09-07T06:14:48.251841Z","shell.execute_reply":"2025-09-07T06:14:52.237093Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Prepare dataset- Casia B - Merge the frams in the dataset into pkl format","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nsrc = Path(\"/kaggle/input/casia-b\")\n\nif src.exists():\n    print(\"Input directory is exist\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:36:00.663204Z","iopub.execute_input":"2025-09-25T00:36:00.663746Z","iopub.status.idle":"2025-09-25T00:36:00.670852Z","shell.execute_reply.started":"2025-09-25T00:36:00.663715Z","shell.execute_reply":"2025-09-25T00:36:00.669607Z"}},"outputs":[{"name":"stdout","text":"Input directory is exist\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import shutil \nsrc = \"/kaggle/input/casia-b\" \ndst = \"/kaggle/working/casia-b\" \n     \nshutil.copytree(src, dst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:55:17.990288Z","iopub.execute_input":"2025-09-28T13:55:17.991687Z","iopub.status.idle":"2025-09-28T13:55:18.043953Z","shell.execute_reply.started":"2025-09-28T13:55:17.991638Z","shell.execute_reply":"2025-09-28T13:55:18.042970Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3703645335.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/working/casia-b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m    570\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shutil.copytree\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/casia-b'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/casia-b'","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"!python3 OpenGait/datasets/pretreatment.py --input_path \"/kaggle/working/casia-b/output\" --output_path \"/kaggle/working/CASIA-B-pkl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T04:32:14.261753Z","iopub.execute_input":"2025-09-25T04:32:14.262121Z","iopub.status.idle":"2025-09-25T04:40:29.754089Z","shell.execute_reply.started":"2025-09-25T04:32:14.262093Z","shell.execute_reply":"2025-09-25T04:40:29.752926Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Pretreating: 100%|████████████████████| 13592/13592 [07:57<00:00, 28.47folder/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Training the Model with CASIA B","metadata":{}},{"cell_type":"code","source":"cd OpenGait","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T00:55:19.905475Z","iopub.execute_input":"2025-10-01T00:55:19.906184Z","iopub.status.idle":"2025-10-01T00:55:19.913468Z","shell.execute_reply.started":"2025-10-01T00:55:19.906159Z","shell.execute_reply":"2025-10-01T00:55:19.912890Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/OpenGait\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import yaml\n\n# Load the existing config\nwith open(\"/kaggle/working/OpenGait/configs/gaitgl/gaitgl.yaml\", \"r\") as f:\n    config = yaml.safe_load(f)\n\n# Make key changes\nconfig[\"data_cfg\"][\"dataset_root\"] = \"/kaggle/working/CASIA-B-pkl\"\nconfig[\"evaluator_cfg\"][\"restore_hint\"] = 80000\nconfig[\"evaluator_cfg\"][\"sampler\"][\"batch_size\"] = 2\nconfig[\"trainer_cfg\"][\"with_test\"] = False\nconfig[\"trainer_cfg\"][\"restore_hint\"] = 70000\n\n# Save the modified config\noutput_path = \"/kaggle/working/OpenGait/configs/gaitgl/gaitgl.yaml\"\nwith open(output_path, \"w\") as f:\n    yaml.dump(config, f, default_flow_style=False)\n\n# Reload and print the updated config\nwith open(output_path, \"r\") as f:\n    updated_config = f.read()\n\nprint(\"✅ Configuration updated and saved to gaitgl_geta.yaml\\n\")\nprint(\"📄 Updated YAML contents:\\n\")\nprint(updated_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:20:53.916388Z","iopub.execute_input":"2025-10-01T17:20:53.916672Z","iopub.status.idle":"2025-10-01T17:20:53.947199Z","shell.execute_reply.started":"2025-10-01T17:20:53.916651Z","shell.execute_reply":"2025-10-01T17:20:53.946647Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"✅ Configuration updated and saved to gaitgl_geta.yaml\n\n📄 Updated YAML contents:\n\ndata_cfg:\n  dataset_name: CASIA-B\n  dataset_partition: ./datasets/CASIA-B/CASIA-B.json\n  dataset_root: /kaggle/working/CASIA-B-pkl\n  num_workers: 1\n  remove_no_gallery: false\n  test_dataset_name: CASIA-B\nevaluator_cfg:\n  enable_float16: false\n  restore_ckpt_strict: true\n  restore_hint: 80000\n  sampler:\n    batch_size: 2\n    sample_type: all_ordered\n    type: InferenceSampler\n  save_name: GaitGL\nloss_cfg:\n- log_prefix: triplet\n  loss_term_weight: 1.0\n  margin: 0.2\n  type: TripletLoss\n- label_smooth: false\n  log_accuracy: true\n  log_prefix: softmax\n  loss_term_weight: 1.0\n  scale: 1\n  type: CrossEntropyLoss\nmodel_cfg:\n  channels:\n  - 32\n  - 64\n  - 128\n  class_num: 74\n  model: GaitGL\noptimizer_cfg:\n  lr: 0.0001\n  solver: Adam\n  weight_decay: 0.0005\nscheduler_cfg:\n  gamma: 0.1\n  milestones:\n  - 70000\n  scheduler: MultiStepLR\ntrainer_cfg:\n  enable_float16: true\n  log_iter: 100\n  restore_ckpt_strict: true\n  restore_hint: 70000\n  sampler:\n    batch_shuffle: true\n    batch_size:\n    - 8\n    - 8\n    frames_num_fixed: 30\n    frames_skip_num: 0\n    sample_type: fixed_ordered\n    type: TripletSampler\n  save_iter: 10000\n  save_name: GaitGL\n  sync_BN: true\n  total_iter: 80000\n  with_test: false\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import yaml\n\n# Load the existing config\nwith open(\"/kaggle/working/geta_gaitGL/OpenGait/configs/gaitgl/gaitgl_geta.yaml\", \"r\") as f:\n    config = yaml.safe_load(f)\n\n# Make key changes\nconfig[\"data_cfg\"][\"dataset_root\"] = \"/kaggle/working/CASIA-B-pkl\"\nconfig[\"evaluator_cfg\"][\"restore_hint\"] = 80000\nconfig[\"evaluator_cfg\"][\"sampler\"][\"batch_size\"] = 2\nconfig[\"trainer_cfg\"][\"with_test\"] = False\nconfig[\"trainer_cfg\"][\"restore_hint\"] = 0\n\n# Save the modified config\noutput_path = \"/kaggle/working/geta_gaitGL/OpenGait/configs/gaitgl/gaitgl_geta.yaml\"\nwith open(output_path, \"w\") as f:\n    yaml.dump(config, f, default_flow_style=False)\n\n# Reload and print the updated config\nwith open(output_path, \"r\") as f:\n    updated_config = f.read()\n\nprint(\"✅ Configuration updated and saved to gaitgl_geta.yaml\\n\")\nprint(\"📄 Updated YAML contents:\\n\")\nprint(updated_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:11:24.005312Z","iopub.execute_input":"2025-10-01T18:11:24.005600Z","iopub.status.idle":"2025-10-01T18:11:24.021768Z","shell.execute_reply.started":"2025-10-01T18:11:24.005576Z","shell.execute_reply":"2025-10-01T18:11:24.021181Z"}},"outputs":[{"name":"stdout","text":"✅ Configuration updated and saved to gaitgl_geta.yaml\n\n📄 Updated YAML contents:\n\ncompression_optimizer: geta\ndata_cfg:\n  dataset_name: CASIA-B\n  dataset_partition: ./datasets/CASIA-B/CASIA-B.json\n  dataset_root: /kaggle/working/CASIA-B-pkl\n  num_workers: 1\n  remove_no_gallery: false\n  test_dataset_name: CASIA-B\nevaluator_cfg:\n  enable_float16: false\n  restore_ckpt_strict: true\n  restore_hint: 80000\n  sampler:\n    batch_size: 2\n    sample_type: all_ordered\n    type: InferenceSampler\n  save_name: GaitGL_GETA\ngeta_optimizer_cfg:\n  first_momentum: 0.9\n  lr: 0.0001\n  lr_quant: 0.001\n  pruning_periods: 10\n  pruning_steps: 20000\n  start_pruning_step: 15000\n  target_group_sparsity: 0.3\n  variant: adam\n  weight_decay: 0.0005\nhesso_optimizer_cfg:\n  lr: 0.0001\n  pruning_periods: 10\n  pruning_steps: 20000\n  start_pruning_step: 10000\n  target_group_sparsity: 0.5\n  variant: adam\n  weight_decay: 0.0005\nloss_cfg:\n- log_prefix: triplet\n  loss_term_weight: 1.0\n  margin: 0.2\n  type: TripletLoss\n- label_smooth: false\n  log_accuracy: true\n  log_prefix: softmax\n  loss_term_weight: 1.0\n  scale: 1\n  type: CrossEntropyLoss\nmodel_cfg:\n  activation_quantize: true\n  channels:\n  - 32\n  - 64\n  - 128\n  class_num: 74\n  model: GaitGLGeta\n  quantize: true\nscheduler_cfg:\n  gamma: 0.1\n  milestones:\n  - 70000\n  scheduler: MultiStepLR\ntrainer_cfg:\n  compression_dir: ./output/compressed_models\n  enable_float16: true\n  log_iter: 100\n  restore_ckpt_strict: true\n  restore_hint: 0\n  sampler:\n    batch_size:\n    - 8\n    - 8\n    frames_num_fixed: 30\n    frames_skip_num: 0\n    sample_type: fixed_ordered\n    type: TripletSampler\n  save_iter: 10000\n  save_name: GaitGL_GETA\n  sync_BN: true\n  total_iter: 80000\n  with_test: false\n\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"cd /kaggle/working/geta_gaitGL/OpenGait","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:12:13.443249Z","iopub.execute_input":"2025-10-01T18:12:13.443517Z","iopub.status.idle":"2025-10-01T18:12:13.448727Z","shell.execute_reply.started":"2025-10-01T18:12:13.443496Z","shell.execute_reply":"2025-10-01T18:12:13.448173Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/geta_gaitGL/OpenGait\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=2 opengait/main_geta.py --cfgs ./configs/gaitgl/gaitgl.yaml --phase train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:52:41.271522Z","iopub.execute_input":"2025-10-01T17:52:41.271705Z","iopub.status.idle":"2025-10-01T17:52:43.661820Z","shell.execute_reply.started":"2025-10-01T17:52:41.271686Z","shell.execute_reply":"2025-10-01T17:52:43.661041Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  main()\nW1001 17:52:43.116000 165 torch/distributed/run.py:792] \nW1001 17:52:43.116000 165 torch/distributed/run.py:792] *****************************************\nW1001 17:52:43.116000 165 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW1001 17:52:43.116000 165 torch/distributed/run.py:792] *****************************************\n/usr/bin/python3: can't open file '/kaggle/working/opengait/main.py': [Errno 2] No such file or directory\n/usr/bin/python3: can't open file '/kaggle/working/opengait/main.py': [Errno 2] No such file or directory\nE1001 17:52:43.225000 165 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 0 (pid: 168) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py\", line 208, in <module>\n    main()\n  File \"/usr/local/lib/python3.11/dist-packages/typing_extensions.py\", line 2950, in wrapper\n    return arg(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py\", line 204, in main\n    launch(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py\", line 189, in launch\n    run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nopengait/main.py FAILED\n------------------------------------------------------------\nFailures:\n[1]:\n  time      : 2025-10-01_17:52:43\n  host      : 58d9f1956df6\n  rank      : 1 (local_rank: 1)\n  exitcode  : 2 (pid: 169)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-10-01_17:52:43\n  host      : 58d9f1956df6\n  rank      : 0 (local_rank: 0)\n  exitcode  : 2 (pid: 168)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=2 opengait/main.py --cfgs ./configs/gaitgl/gaitgl.yaml --phase test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:08:39.513212Z","iopub.execute_input":"2025-10-01T18:08:39.513497Z","iopub.status.idle":"2025-10-01T18:10:04.481674Z","shell.execute_reply.started":"2025-10-01T18:08:39.513473Z","shell.execute_reply":"2025-10-01T18:10:04.480787Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  main()\nW1001 18:08:41.179000 190 torch/distributed/run.py:792] \nW1001 18:08:41.179000 190 torch/distributed/run.py:792] *****************************************\nW1001 18:08:41.179000 190 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW1001 18:08:41.179000 190 torch/distributed/run.py:792] *****************************************\n2025-10-01 18:08:44.585313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-10-01 18:08:44.596001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759342124.607496     194 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759342124.613688     194 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759342124.616506     193 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759342124.622607     193 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-10-01 18:08:49] [INFO]: {'enable_float16': False, 'restore_ckpt_strict': True, 'restore_hint': 80000, 'save_name': 'GaitGL', 'eval_func': 'evaluate_indoor_dataset', 'sampler': {'batch_size': 2, 'sample_type': 'all_ordered', 'type': 'InferenceSampler'}, 'transform': [{'type': 'BaseSilCuttingTransform'}], 'metric': 'euc', 'cross_view_gallery': False}\n[2025-10-01 18:08:49] [INFO]: {'model': 'GaitGL', 'channels': [32, 64, 128], 'class_num': 74}\n[2025-10-01 18:08:49] [INFO]: {'dataset_name': 'CASIA-B', 'dataset_root': '/kaggle/working/CASIA-B-pkl', 'num_workers': 1, 'dataset_partition': './datasets/CASIA-B/CASIA-B.json', 'remove_no_gallery': False, 'cache': False, 'test_dataset_name': 'CASIA-B'}\n[2025-10-01 18:08:49] [INFO]: -------- Test Pid List --------\n[2025-10-01 18:08:49] [INFO]: [075, 076, ..., 124]\n[2025-10-01 18:08:49] [INFO]: Restore Parameters from output/CASIA-B/GaitGL/GaitGL/checkpoints/GaitGL-80000.pt !!!\n[2025-10-01 18:08:50] [INFO]: Parameters Count: 3.09667M\n[2025-10-01 18:08:50] [INFO]: Model Initialization Finished!\nTransforming: 100%|█████████████████████████| 5485/5485 [01:03<00:00, 86.20it/s]\n[2025-10-01 18:10:01] [INFO]: ===Rank-1 (Exclude identical-view cases)===\n[2025-10-01 18:10:01] [INFO]: NM@R1: [96.30 98.10 99.10 97.80 96.50 94.80 97.10 99.10 99.30 98.50 93.20]\n[2025-10-01 18:10:01] [INFO]: BG@R1: [92.90 96.20 97.00 96.26 94.10 89.40 92.80 96.90 98.50 96.47 91.60]\n[2025-10-01 18:10:01] [INFO]: CL@R1: [76.90 90.80 93.00 89.30 82.90 76.30 82.80 87.70 89.00 84.70 69.70]\n[2025-10-01 18:10:01] [INFO]: NM@R1: 97.25%\tBG@R1: 94.74%\tCL@R1: 83.92%\t\n[rank0]:[W1001 18:10:02.908527131 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=2 opengait/main.py --cfgs ./configs/gaitgl/gaitgl.yaml --phase train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T13:39:38.910975Z","iopub.execute_input":"2025-10-01T13:39:38.911458Z","iopub.status.idle":"2025-10-01T14:22:09.099001Z","shell.execute_reply.started":"2025-10-01T13:39:38.911434Z","shell.execute_reply":"2025-10-01T14:22:09.098257Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  main()\nW1001 13:39:40.621000 84 torch/distributed/run.py:792] \nW1001 13:39:40.621000 84 torch/distributed/run.py:792] *****************************************\nW1001 13:39:40.621000 84 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW1001 13:39:40.621000 84 torch/distributed/run.py:792] *****************************************\n2025-10-01 13:39:48.763723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-10-01 13:39:48.763724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759325989.014671      88 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759325989.014654      87 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759325989.093291      88 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1759325989.093303      87 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-10-01 13:40:04] [INFO]: {'find_unused_parameters': False, 'enable_float16': True, 'with_test': False, 'fix_BN': False, 'log_iter': 100, 'restore_ckpt_strict': True, 'optimizer_reset': False, 'scheduler_reset': False, 'restore_hint': 70000, 'save_iter': 10000, 'save_name': 'GaitGL', 'sync_BN': True, 'total_iter': 80000, 'sampler': {'batch_shuffle': True, 'batch_size': [8, 8], 'frames_num_fixed': 30, 'frames_num_max': 50, 'frames_num_min': 25, 'sample_type': 'fixed_ordered', 'type': 'TripletSampler', 'frames_skip_num': 0}, 'transform': [{'type': 'BaseSilCuttingTransform'}]}\n[2025-10-01 13:40:04] [INFO]: {'model': 'GaitGL', 'channels': [32, 64, 128], 'class_num': 74}\n[2025-10-01 13:40:04] [INFO]: {'dataset_name': 'CASIA-B', 'dataset_root': '/kaggle/working/CASIA-B-pkl', 'num_workers': 1, 'dataset_partition': './datasets/CASIA-B/CASIA-B.json', 'remove_no_gallery': False, 'cache': False, 'test_dataset_name': 'CASIA-B'}\n[2025-10-01 13:40:04] [INFO]: -------- Train Pid List --------\n[2025-10-01 13:40:04] [INFO]: [001, 002, ..., 074]\n[2025-10-01 13:40:04] [INFO]: {'lr': 0.0001, 'momentum': 0.9, 'solver': 'Adam', 'weight_decay': 0.0005}\n[2025-10-01 13:40:04] [INFO]: {'gamma': 0.1, 'milestones': [70000], 'scheduler': 'MultiStepLR'}\n[2025-10-01 13:40:05] [INFO]: Restore Parameters from output/CASIA-B/GaitGL/GaitGL/checkpoints/GaitGL-70000.pt !!!\n[2025-10-01 13:40:06] [INFO]: Parameters Count: 3.09667M\n[2025-10-01 13:40:06] [INFO]: Model Initialization Finished!\n[2025-10-01 13:40:32] [INFO]: Iteration 70100, Cost 29.82s, triplet_loss=1.0822, triplet_hard_loss=5.1222, triplet_loss_num=663.1389, triplet_mean_dist=19.2014, softmax_loss=0.6318, softmax_accuracy=0.9321\n[2025-10-01 13:40:56] [INFO]: Iteration 70200, Cost 24.04s, triplet_loss=1.0830, triplet_hard_loss=5.1325, triplet_loss_num=625.6908, triplet_mean_dist=19.2699, softmax_loss=0.5968, softmax_accuracy=0.9403\n[2025-10-01 13:41:20] [INFO]: Iteration 70300, Cost 24.64s, triplet_loss=1.0781, triplet_hard_loss=5.0800, triplet_loss_num=608.1990, triplet_mean_dist=19.3416, softmax_loss=0.5910, softmax_accuracy=0.9416\n[2025-10-01 13:41:45] [INFO]: Iteration 70400, Cost 25.10s, triplet_loss=1.0757, triplet_hard_loss=5.0725, triplet_loss_num=621.3191, triplet_mean_dist=19.3636, softmax_loss=0.5830, softmax_accuracy=0.9433\n[2025-10-01 13:42:11] [INFO]: Iteration 70500, Cost 25.64s, triplet_loss=1.0791, triplet_hard_loss=5.1054, triplet_loss_num=653.5736, triplet_mean_dist=19.3335, softmax_loss=0.5922, softmax_accuracy=0.9397\n[2025-10-01 13:42:36] [INFO]: Iteration 70600, Cost 25.46s, triplet_loss=1.0703, triplet_hard_loss=5.0441, triplet_loss_num=626.5862, triplet_mean_dist=19.3420, softmax_loss=0.5853, softmax_accuracy=0.9437\n[2025-10-01 13:43:02] [INFO]: Iteration 70700, Cost 25.17s, triplet_loss=1.0787, triplet_hard_loss=5.0613, triplet_loss_num=634.6917, triplet_mean_dist=19.3686, softmax_loss=0.5930, softmax_accuracy=0.9415\n[2025-10-01 13:43:27] [INFO]: Iteration 70800, Cost 25.14s, triplet_loss=1.0745, triplet_hard_loss=5.0681, triplet_loss_num=634.6820, triplet_mean_dist=19.3389, softmax_loss=0.6017, softmax_accuracy=0.9377\n[2025-10-01 13:43:52] [INFO]: Iteration 70900, Cost 25.23s, triplet_loss=1.0580, triplet_hard_loss=4.9808, triplet_loss_num=600.7065, triplet_mean_dist=19.3700, softmax_loss=0.5751, softmax_accuracy=0.9460\n[2025-10-01 13:44:17] [INFO]: Iteration 71000, Cost 25.22s, triplet_loss=1.0641, triplet_hard_loss=4.9835, triplet_loss_num=602.2502, triplet_mean_dist=19.3842, softmax_loss=0.5744, softmax_accuracy=0.9452\n[2025-10-01 13:44:42] [INFO]: Iteration 71100, Cost 25.17s, triplet_loss=1.0605, triplet_hard_loss=4.9935, triplet_loss_num=621.4294, triplet_mean_dist=19.3473, softmax_loss=0.5837, softmax_accuracy=0.9432\n[2025-10-01 13:45:08] [INFO]: Iteration 71200, Cost 25.27s, triplet_loss=1.0600, triplet_hard_loss=4.9403, triplet_loss_num=588.2087, triplet_mean_dist=19.4280, softmax_loss=0.5782, softmax_accuracy=0.9446\n[2025-10-01 13:45:33] [INFO]: Iteration 71300, Cost 25.16s, triplet_loss=1.0631, triplet_hard_loss=4.9948, triplet_loss_num=621.1520, triplet_mean_dist=19.3748, softmax_loss=0.5791, softmax_accuracy=0.9428\n[2025-10-01 13:45:58] [INFO]: Iteration 71400, Cost 25.11s, triplet_loss=1.0557, triplet_hard_loss=4.9144, triplet_loss_num=560.9651, triplet_mean_dist=19.4806, softmax_loss=0.5716, softmax_accuracy=0.9456\n[2025-10-01 13:46:23] [INFO]: Iteration 71500, Cost 25.24s, triplet_loss=1.0630, triplet_hard_loss=5.0129, triplet_loss_num=626.0209, triplet_mean_dist=19.3117, softmax_loss=0.5724, softmax_accuracy=0.9470\n[2025-10-01 13:46:48] [INFO]: Iteration 71600, Cost 25.09s, triplet_loss=1.0657, triplet_hard_loss=4.9823, triplet_loss_num=596.3918, triplet_mean_dist=19.3686, softmax_loss=0.5781, softmax_accuracy=0.9450\n[2025-10-01 13:47:13] [INFO]: Iteration 71700, Cost 25.20s, triplet_loss=1.0550, triplet_hard_loss=4.9427, triplet_loss_num=595.5539, triplet_mean_dist=19.3754, softmax_loss=0.5754, softmax_accuracy=0.9449\n[2025-10-01 13:47:39] [INFO]: Iteration 71800, Cost 25.28s, triplet_loss=1.0709, triplet_hard_loss=5.0148, triplet_loss_num=612.6856, triplet_mean_dist=19.4019, softmax_loss=0.5835, softmax_accuracy=0.9426\n[2025-10-01 13:48:04] [INFO]: Iteration 71900, Cost 25.12s, triplet_loss=1.0584, triplet_hard_loss=4.9567, triplet_loss_num=594.2455, triplet_mean_dist=19.4126, softmax_loss=0.5740, softmax_accuracy=0.9446\n[2025-10-01 13:48:29] [INFO]: Iteration 72000, Cost 25.49s, triplet_loss=1.0597, triplet_hard_loss=4.9531, triplet_loss_num=580.9662, triplet_mean_dist=19.4317, softmax_loss=0.5727, softmax_accuracy=0.9451\n[2025-10-01 13:48:55] [INFO]: Iteration 72100, Cost 25.24s, triplet_loss=1.0749, triplet_hard_loss=5.0357, triplet_loss_num=622.4188, triplet_mean_dist=19.3820, softmax_loss=0.5840, softmax_accuracy=0.9431\n[2025-10-01 13:49:20] [INFO]: Iteration 72200, Cost 25.16s, triplet_loss=1.0520, triplet_hard_loss=4.9039, triplet_loss_num=573.7098, triplet_mean_dist=19.4307, softmax_loss=0.5770, softmax_accuracy=0.9455\n[2025-10-01 13:49:45] [INFO]: Iteration 72300, Cost 25.17s, triplet_loss=1.0570, triplet_hard_loss=4.9384, triplet_loss_num=586.3030, triplet_mean_dist=19.4639, softmax_loss=0.5751, softmax_accuracy=0.9461\n[2025-10-01 13:50:10] [INFO]: Iteration 72400, Cost 25.13s, triplet_loss=1.0532, triplet_hard_loss=4.9266, triplet_loss_num=592.9537, triplet_mean_dist=19.3945, softmax_loss=0.5685, softmax_accuracy=0.9469\n[2025-10-01 13:50:35] [INFO]: Iteration 72500, Cost 25.29s, triplet_loss=1.0606, triplet_hard_loss=4.9931, triplet_loss_num=587.7883, triplet_mean_dist=19.4252, softmax_loss=0.5710, softmax_accuracy=0.9469\n[2025-10-01 13:51:01] [INFO]: Iteration 72600, Cost 25.20s, triplet_loss=1.0574, triplet_hard_loss=4.9472, triplet_loss_num=589.6909, triplet_mean_dist=19.3990, softmax_loss=0.5795, softmax_accuracy=0.9435\n[2025-10-01 13:51:26] [INFO]: Iteration 72700, Cost 25.25s, triplet_loss=1.0634, triplet_hard_loss=4.9801, triplet_loss_num=599.2130, triplet_mean_dist=19.3900, softmax_loss=0.5733, softmax_accuracy=0.9457\n[2025-10-01 13:51:51] [INFO]: Iteration 72800, Cost 25.23s, triplet_loss=1.0484, triplet_hard_loss=4.8825, triplet_loss_num=573.2629, triplet_mean_dist=19.3881, softmax_loss=0.5644, softmax_accuracy=0.9466\n[2025-10-01 13:52:16] [INFO]: Iteration 72900, Cost 25.16s, triplet_loss=1.0517, triplet_hard_loss=4.9077, triplet_loss_num=583.9945, triplet_mean_dist=19.4071, softmax_loss=0.5786, softmax_accuracy=0.9449\n[2025-10-01 13:52:41] [INFO]: Iteration 73000, Cost 25.24s, triplet_loss=1.0505, triplet_hard_loss=4.8821, triplet_loss_num=574.3766, triplet_mean_dist=19.4484, softmax_loss=0.5691, softmax_accuracy=0.9463\n[2025-10-01 13:53:07] [INFO]: Iteration 73100, Cost 25.20s, triplet_loss=1.0702, triplet_hard_loss=5.0197, triplet_loss_num=607.1436, triplet_mean_dist=19.3810, softmax_loss=0.5730, softmax_accuracy=0.9465\n[2025-10-01 13:53:32] [INFO]: Iteration 73200, Cost 25.11s, triplet_loss=1.0475, triplet_hard_loss=4.8934, triplet_loss_num=576.7845, triplet_mean_dist=19.4256, softmax_loss=0.5736, softmax_accuracy=0.9461\n[2025-10-01 13:53:57] [INFO]: Iteration 73300, Cost 25.25s, triplet_loss=1.0630, triplet_hard_loss=4.9957, triplet_loss_num=640.7706, triplet_mean_dist=19.3246, softmax_loss=0.5837, softmax_accuracy=0.9428\n[2025-10-01 13:54:22] [INFO]: Iteration 73400, Cost 25.26s, triplet_loss=1.0388, triplet_hard_loss=4.8621, triplet_loss_num=582.3444, triplet_mean_dist=19.3247, softmax_loss=0.5682, softmax_accuracy=0.9481\n[2025-10-01 13:54:47] [INFO]: Iteration 73500, Cost 25.16s, triplet_loss=1.0648, triplet_hard_loss=5.0149, triplet_loss_num=628.5481, triplet_mean_dist=19.3576, softmax_loss=0.5800, softmax_accuracy=0.9447\n[2025-10-01 13:55:13] [INFO]: Iteration 73600, Cost 25.15s, triplet_loss=1.0482, triplet_hard_loss=4.8788, triplet_loss_num=590.2572, triplet_mean_dist=19.3819, softmax_loss=0.5660, softmax_accuracy=0.9474\n[2025-10-01 13:55:38] [INFO]: Iteration 73700, Cost 25.10s, triplet_loss=1.0575, triplet_hard_loss=4.9802, triplet_loss_num=606.4547, triplet_mean_dist=19.3221, softmax_loss=0.5744, softmax_accuracy=0.9457\n[2025-10-01 13:56:03] [INFO]: Iteration 73800, Cost 25.19s, triplet_loss=1.0578, triplet_hard_loss=4.9473, triplet_loss_num=589.3225, triplet_mean_dist=19.3893, softmax_loss=0.5705, softmax_accuracy=0.9455\n[2025-10-01 13:56:28] [INFO]: Iteration 73900, Cost 25.01s, triplet_loss=1.0521, triplet_hard_loss=4.9077, triplet_loss_num=598.9733, triplet_mean_dist=19.4285, softmax_loss=0.5782, softmax_accuracy=0.9438\n[2025-10-01 13:56:53] [INFO]: Iteration 74000, Cost 25.20s, triplet_loss=1.0534, triplet_hard_loss=4.9292, triplet_loss_num=610.2028, triplet_mean_dist=19.3643, softmax_loss=0.5781, softmax_accuracy=0.9458\n[2025-10-01 13:57:19] [INFO]: Iteration 74100, Cost 25.75s, triplet_loss=1.0574, triplet_hard_loss=4.9644, triplet_loss_num=605.9303, triplet_mean_dist=19.3626, softmax_loss=0.5741, softmax_accuracy=0.9459\n[2025-10-01 13:57:44] [INFO]: Iteration 74200, Cost 25.27s, triplet_loss=1.0598, triplet_hard_loss=4.9528, triplet_loss_num=605.4309, triplet_mean_dist=19.3503, softmax_loss=0.5665, softmax_accuracy=0.9480\n[2025-10-01 13:58:09] [INFO]: Iteration 74300, Cost 25.13s, triplet_loss=1.0607, triplet_hard_loss=4.9732, triplet_loss_num=604.8717, triplet_mean_dist=19.3835, softmax_loss=0.5824, softmax_accuracy=0.9429\n[2025-10-01 13:58:34] [INFO]: Iteration 74400, Cost 25.10s, triplet_loss=1.0493, triplet_hard_loss=4.9020, triplet_loss_num=583.0520, triplet_mean_dist=19.3664, softmax_loss=0.5719, softmax_accuracy=0.9476\n[2025-10-01 13:59:00] [INFO]: Iteration 74500, Cost 25.34s, triplet_loss=1.0660, triplet_hard_loss=4.9843, triplet_loss_num=604.7847, triplet_mean_dist=19.3922, softmax_loss=0.5767, softmax_accuracy=0.9453\n[2025-10-01 13:59:25] [INFO]: Iteration 74600, Cost 25.20s, triplet_loss=1.0438, triplet_hard_loss=4.8932, triplet_loss_num=584.3505, triplet_mean_dist=19.3962, softmax_loss=0.5676, softmax_accuracy=0.9481\n[2025-10-01 13:59:50] [INFO]: Iteration 74700, Cost 25.16s, triplet_loss=1.0491, triplet_hard_loss=4.8787, triplet_loss_num=582.3887, triplet_mean_dist=19.4386, softmax_loss=0.5736, softmax_accuracy=0.9456\n[2025-10-01 14:00:15] [INFO]: Iteration 74800, Cost 25.27s, triplet_loss=1.0420, triplet_hard_loss=4.8342, triplet_loss_num=564.5008, triplet_mean_dist=19.4372, softmax_loss=0.5621, softmax_accuracy=0.9481\n[2025-10-01 14:00:40] [INFO]: Iteration 74900, Cost 25.21s, triplet_loss=1.0457, triplet_hard_loss=4.8817, triplet_loss_num=592.2366, triplet_mean_dist=19.4406, softmax_loss=0.5733, softmax_accuracy=0.9457\n[2025-10-01 14:01:06] [INFO]: Iteration 75000, Cost 25.29s, triplet_loss=1.0476, triplet_hard_loss=4.8924, triplet_loss_num=578.1461, triplet_mean_dist=19.4269, softmax_loss=0.5679, softmax_accuracy=0.9483\n[2025-10-01 14:01:31] [INFO]: Iteration 75100, Cost 25.18s, triplet_loss=1.0528, triplet_hard_loss=4.9252, triplet_loss_num=588.1894, triplet_mean_dist=19.4354, softmax_loss=0.5775, softmax_accuracy=0.9445\n[2025-10-01 14:01:56] [INFO]: Iteration 75200, Cost 25.27s, triplet_loss=1.0435, triplet_hard_loss=4.8556, triplet_loss_num=581.8522, triplet_mean_dist=19.3872, softmax_loss=0.5666, softmax_accuracy=0.9482\n[2025-10-01 14:02:22] [INFO]: Iteration 75300, Cost 25.29s, triplet_loss=1.0511, triplet_hard_loss=4.9026, triplet_loss_num=599.7414, triplet_mean_dist=19.3998, softmax_loss=0.5712, softmax_accuracy=0.9475\n[2025-10-01 14:02:47] [INFO]: Iteration 75400, Cost 25.31s, triplet_loss=1.0426, triplet_hard_loss=4.8615, triplet_loss_num=575.8214, triplet_mean_dist=19.4220, softmax_loss=0.5721, softmax_accuracy=0.9462\n[2025-10-01 14:03:12] [INFO]: Iteration 75500, Cost 25.23s, triplet_loss=1.0480, triplet_hard_loss=4.8765, triplet_loss_num=579.8039, triplet_mean_dist=19.4101, softmax_loss=0.5745, softmax_accuracy=0.9465\n[2025-10-01 14:03:37] [INFO]: Iteration 75600, Cost 25.11s, triplet_loss=1.0518, triplet_hard_loss=4.9195, triplet_loss_num=597.0733, triplet_mean_dist=19.4063, softmax_loss=0.5761, softmax_accuracy=0.9449\n[2025-10-01 14:04:02] [INFO]: Iteration 75700, Cost 25.15s, triplet_loss=1.0450, triplet_hard_loss=4.8651, triplet_loss_num=569.0323, triplet_mean_dist=19.4388, softmax_loss=0.5677, softmax_accuracy=0.9469\n[2025-10-01 14:04:28] [INFO]: Iteration 75800, Cost 25.24s, triplet_loss=1.0303, triplet_hard_loss=4.7979, triplet_loss_num=572.9655, triplet_mean_dist=19.4150, softmax_loss=0.5747, softmax_accuracy=0.9463\n[2025-10-01 14:04:53] [INFO]: Iteration 75900, Cost 25.00s, triplet_loss=1.0494, triplet_hard_loss=4.9153, triplet_loss_num=591.2109, triplet_mean_dist=19.3500, softmax_loss=0.5605, softmax_accuracy=0.9488\n[2025-10-01 14:05:18] [INFO]: Iteration 76000, Cost 25.14s, triplet_loss=1.0528, triplet_hard_loss=4.9177, triplet_loss_num=600.1752, triplet_mean_dist=19.3890, softmax_loss=0.5723, softmax_accuracy=0.9468\n[2025-10-01 14:05:43] [INFO]: Iteration 76100, Cost 25.73s, triplet_loss=1.0499, triplet_hard_loss=4.8996, triplet_loss_num=568.4852, triplet_mean_dist=19.4663, softmax_loss=0.5682, softmax_accuracy=0.9479\n[2025-10-01 14:06:09] [INFO]: Iteration 76200, Cost 25.17s, triplet_loss=1.0460, triplet_hard_loss=4.8826, triplet_loss_num=583.6552, triplet_mean_dist=19.3814, softmax_loss=0.5624, softmax_accuracy=0.9497\n[2025-10-01 14:06:34] [INFO]: Iteration 76300, Cost 25.17s, triplet_loss=1.0584, triplet_hard_loss=4.9645, triplet_loss_num=610.3969, triplet_mean_dist=19.3637, softmax_loss=0.5694, softmax_accuracy=0.9473\n[2025-10-01 14:06:59] [INFO]: Iteration 76400, Cost 25.13s, triplet_loss=1.0555, triplet_hard_loss=4.9354, triplet_loss_num=586.8527, triplet_mean_dist=19.4502, softmax_loss=0.5748, softmax_accuracy=0.9452\n[2025-10-01 14:07:24] [INFO]: Iteration 76500, Cost 25.10s, triplet_loss=1.0570, triplet_hard_loss=4.9766, triplet_loss_num=621.2598, triplet_mean_dist=19.3469, softmax_loss=0.5783, softmax_accuracy=0.9449\n[2025-10-01 14:07:49] [INFO]: Iteration 76600, Cost 25.07s, triplet_loss=1.0443, triplet_hard_loss=4.9022, triplet_loss_num=597.1992, triplet_mean_dist=19.3560, softmax_loss=0.5719, softmax_accuracy=0.9468\n[2025-10-01 14:08:14] [INFO]: Iteration 76700, Cost 25.11s, triplet_loss=1.0473, triplet_hard_loss=4.8882, triplet_loss_num=585.7026, triplet_mean_dist=19.3875, softmax_loss=0.5741, softmax_accuracy=0.9457\n[2025-10-01 14:08:39] [INFO]: Iteration 76800, Cost 25.19s, triplet_loss=1.0491, triplet_hard_loss=4.9288, triplet_loss_num=593.1856, triplet_mean_dist=19.3905, softmax_loss=0.5816, softmax_accuracy=0.9440\n[2025-10-01 14:09:05] [INFO]: Iteration 76900, Cost 25.12s, triplet_loss=1.0484, triplet_hard_loss=4.8834, triplet_loss_num=590.7679, triplet_mean_dist=19.3868, softmax_loss=0.5730, softmax_accuracy=0.9458\n[2025-10-01 14:09:30] [INFO]: Iteration 77000, Cost 25.16s, triplet_loss=1.0516, triplet_hard_loss=4.9123, triplet_loss_num=586.6777, triplet_mean_dist=19.4319, softmax_loss=0.5661, softmax_accuracy=0.9479\n[2025-10-01 14:09:55] [INFO]: Iteration 77100, Cost 25.09s, triplet_loss=1.0584, triplet_hard_loss=4.9632, triplet_loss_num=605.5697, triplet_mean_dist=19.3402, softmax_loss=0.5660, softmax_accuracy=0.9476\n[2025-10-01 14:10:20] [INFO]: Iteration 77200, Cost 25.16s, triplet_loss=1.0439, triplet_hard_loss=4.8733, triplet_loss_num=590.9047, triplet_mean_dist=19.3622, softmax_loss=0.5732, softmax_accuracy=0.9477\n[2025-10-01 14:10:45] [INFO]: Iteration 77300, Cost 25.10s, triplet_loss=1.0465, triplet_hard_loss=4.8841, triplet_loss_num=588.0168, triplet_mean_dist=19.3570, softmax_loss=0.5648, softmax_accuracy=0.9480\n[2025-10-01 14:11:10] [INFO]: Iteration 77400, Cost 25.09s, triplet_loss=1.0598, triplet_hard_loss=4.9769, triplet_loss_num=595.3383, triplet_mean_dist=19.3792, softmax_loss=0.5739, softmax_accuracy=0.9453\n[2025-10-01 14:11:35] [INFO]: Iteration 77500, Cost 25.02s, triplet_loss=1.0517, triplet_hard_loss=4.9477, triplet_loss_num=599.2506, triplet_mean_dist=19.3556, softmax_loss=0.5821, softmax_accuracy=0.9441\n[2025-10-01 14:12:00] [INFO]: Iteration 77600, Cost 25.22s, triplet_loss=1.0414, triplet_hard_loss=4.8430, triplet_loss_num=566.7269, triplet_mean_dist=19.3768, softmax_loss=0.5561, softmax_accuracy=0.9511\n[2025-10-01 14:12:26] [INFO]: Iteration 77700, Cost 25.18s, triplet_loss=1.0418, triplet_hard_loss=4.8751, triplet_loss_num=595.2089, triplet_mean_dist=19.3186, softmax_loss=0.5676, softmax_accuracy=0.9484\n[2025-10-01 14:12:51] [INFO]: Iteration 77800, Cost 25.16s, triplet_loss=1.0587, triplet_hard_loss=4.9769, triplet_loss_num=608.7385, triplet_mean_dist=19.3700, softmax_loss=0.5742, softmax_accuracy=0.9459\n[2025-10-01 14:13:16] [INFO]: Iteration 77900, Cost 25.13s, triplet_loss=1.0425, triplet_hard_loss=4.8660, triplet_loss_num=580.8901, triplet_mean_dist=19.3904, softmax_loss=0.5661, softmax_accuracy=0.9493\n[2025-10-01 14:13:41] [INFO]: Iteration 78000, Cost 25.34s, triplet_loss=1.0409, triplet_hard_loss=4.8568, triplet_loss_num=571.2350, triplet_mean_dist=19.4062, softmax_loss=0.5707, softmax_accuracy=0.9474\n[2025-10-01 14:14:07] [INFO]: Iteration 78100, Cost 25.81s, triplet_loss=1.0485, triplet_hard_loss=4.9043, triplet_loss_num=594.1984, triplet_mean_dist=19.4295, softmax_loss=0.5760, softmax_accuracy=0.9436\n[2025-10-01 14:14:32] [INFO]: Iteration 78200, Cost 25.15s, triplet_loss=1.0453, triplet_hard_loss=4.8296, triplet_loss_num=541.3394, triplet_mean_dist=19.4956, softmax_loss=0.5681, softmax_accuracy=0.9469\n[2025-10-01 14:14:57] [INFO]: Iteration 78300, Cost 25.07s, triplet_loss=1.0512, triplet_hard_loss=4.9176, triplet_loss_num=608.0977, triplet_mean_dist=19.3797, softmax_loss=0.5758, softmax_accuracy=0.9458\n[2025-10-01 14:15:22] [INFO]: Iteration 78400, Cost 25.16s, triplet_loss=1.0487, triplet_hard_loss=4.8876, triplet_loss_num=591.3125, triplet_mean_dist=19.3782, softmax_loss=0.5664, softmax_accuracy=0.9470\n[2025-10-01 14:15:48] [INFO]: Iteration 78500, Cost 25.26s, triplet_loss=1.0547, triplet_hard_loss=4.9326, triplet_loss_num=596.7364, triplet_mean_dist=19.4243, softmax_loss=0.5719, softmax_accuracy=0.9462\n[2025-10-01 14:16:13] [INFO]: Iteration 78600, Cost 25.10s, triplet_loss=1.0511, triplet_hard_loss=4.9078, triplet_loss_num=571.9375, triplet_mean_dist=19.4099, softmax_loss=0.5765, softmax_accuracy=0.9456\n[2025-10-01 14:16:38] [INFO]: Iteration 78700, Cost 25.06s, triplet_loss=1.0563, triplet_hard_loss=4.9568, triplet_loss_num=619.6133, triplet_mean_dist=19.3414, softmax_loss=0.5770, softmax_accuracy=0.9462\n[2025-10-01 14:17:03] [INFO]: Iteration 78800, Cost 25.20s, triplet_loss=1.0462, triplet_hard_loss=4.8855, triplet_loss_num=600.1680, triplet_mean_dist=19.3457, softmax_loss=0.5638, softmax_accuracy=0.9475\n[2025-10-01 14:17:28] [INFO]: Iteration 78900, Cost 25.11s, triplet_loss=1.0405, triplet_hard_loss=4.8509, triplet_loss_num=582.5298, triplet_mean_dist=19.4027, softmax_loss=0.5737, softmax_accuracy=0.9462\n[2025-10-01 14:17:53] [INFO]: Iteration 79000, Cost 25.10s, triplet_loss=1.0358, triplet_hard_loss=4.7785, triplet_loss_num=545.1055, triplet_mean_dist=19.4451, softmax_loss=0.5562, softmax_accuracy=0.9503\n[2025-10-01 14:18:18] [INFO]: Iteration 79100, Cost 25.23s, triplet_loss=1.0523, triplet_hard_loss=4.9090, triplet_loss_num=600.4264, triplet_mean_dist=19.4165, softmax_loss=0.5687, softmax_accuracy=0.9474\n[2025-10-01 14:18:44] [INFO]: Iteration 79200, Cost 25.22s, triplet_loss=1.0490, triplet_hard_loss=4.9105, triplet_loss_num=586.3588, triplet_mean_dist=19.4078, softmax_loss=0.5638, softmax_accuracy=0.9480\n[2025-10-01 14:19:09] [INFO]: Iteration 79300, Cost 25.18s, triplet_loss=1.0466, triplet_hard_loss=4.8867, triplet_loss_num=584.9164, triplet_mean_dist=19.4180, softmax_loss=0.5670, softmax_accuracy=0.9487\n[2025-10-01 14:19:34] [INFO]: Iteration 79400, Cost 25.05s, triplet_loss=1.0578, triplet_hard_loss=4.9446, triplet_loss_num=607.5396, triplet_mean_dist=19.3750, softmax_loss=0.5708, softmax_accuracy=0.9461\n[2025-10-01 14:19:59] [INFO]: Iteration 79500, Cost 25.28s, triplet_loss=1.0445, triplet_hard_loss=4.8696, triplet_loss_num=572.1786, triplet_mean_dist=19.4166, softmax_loss=0.5596, softmax_accuracy=0.9497\n[2025-10-01 14:20:24] [INFO]: Iteration 79600, Cost 24.98s, triplet_loss=1.0497, triplet_hard_loss=4.9282, triplet_loss_num=597.9138, triplet_mean_dist=19.3895, softmax_loss=0.5759, softmax_accuracy=0.9468\n[2025-10-01 14:20:49] [INFO]: Iteration 79700, Cost 25.08s, triplet_loss=1.0433, triplet_hard_loss=4.8707, triplet_loss_num=590.3836, triplet_mean_dist=19.3791, softmax_loss=0.5692, softmax_accuracy=0.9469\n[2025-10-01 14:21:14] [INFO]: Iteration 79800, Cost 25.16s, triplet_loss=1.0473, triplet_hard_loss=4.9045, triplet_loss_num=589.4350, triplet_mean_dist=19.4197, softmax_loss=0.5681, softmax_accuracy=0.9479\n[2025-10-01 14:21:40] [INFO]: Iteration 79900, Cost 25.17s, triplet_loss=1.0402, triplet_hard_loss=4.8624, triplet_loss_num=589.5711, triplet_mean_dist=19.3967, softmax_loss=0.5756, softmax_accuracy=0.9464\n[2025-10-01 14:22:05] [INFO]: Iteration 80000, Cost 25.03s, triplet_loss=1.0496, triplet_hard_loss=4.8994, triplet_loss_num=593.9998, triplet_mean_dist=19.3891, softmax_loss=0.5773, softmax_accuracy=0.9456\n[rank0]:[W1001 14:22:06.832766052 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=2 opengait/main_geta.py --cfgs ./configs/gaitgl/gaitgl_geta.yaml --phase test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:13:55.363180Z","iopub.execute_input":"2025-10-01T18:13:55.363476Z","iopub.status.idle":"2025-10-01T18:15:20.731729Z","shell.execute_reply.started":"2025-10-01T18:13:55.363453Z","shell.execute_reply":"2025-10-01T18:15:20.730998Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  main()\nW1001 18:13:57.110000 231 torch/distributed/run.py:792] \nW1001 18:13:57.110000 231 torch/distributed/run.py:792] *****************************************\nW1001 18:13:57.110000 231 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW1001 18:13:57.110000 231 torch/distributed/run.py:792] *****************************************\n2025-10-01 18:14:00.520325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-10-01 18:14:00.520325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759342440.542224     235 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759342440.542876     234 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759342440.549423     235 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1759342440.549501     234 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-10-01 18:14:05] [INFO]: {'enable_float16': False, 'restore_ckpt_strict': True, 'restore_hint': 80000, 'save_name': 'GaitGL_GETA', 'eval_func': 'evaluate_indoor_dataset', 'sampler': {'batch_size': 2, 'sample_type': 'all_ordered', 'type': 'InferenceSampler'}, 'transform': [{'type': 'BaseSilCuttingTransform'}], 'metric': 'euc', 'cross_view_gallery': False}\n[2025-10-01 18:14:05] [INFO]: {'model': 'GaitGLGeta', 'activation_quantize': True, 'channels': [32, 64, 128], 'class_num': 74, 'quantize': True}\n[2025-10-01 18:14:05] [INFO]: {'dataset_name': 'CASIA-B', 'dataset_root': '/kaggle/working/CASIA-B-pkl', 'num_workers': 1, 'dataset_partition': './datasets/CASIA-B/CASIA-B.json', 'remove_no_gallery': False, 'cache': False, 'test_dataset_name': 'CASIA-B'}\n[2025-10-01 18:14:05] [INFO]: -------- Test Pid List --------\n[2025-10-01 18:14:05] [INFO]: [075, 076, ..., 124]\n[2025-10-01 18:14:05] [INFO]: Restore Parameters from output/CASIA-B/GaitGLGeta/GaitGL_GETA/checkpoints/GaitGL_GETA-80000.pt !!!\n[2025-10-01 18:14:05] [INFO]: Parameters Count: 3.09667M\n[2025-10-01 18:14:05] [INFO]: Model Initialization Finished!\nTransforming: 100%|█████████████████████████| 5485/5485 [01:04<00:00, 84.51it/s]\n[2025-10-01 18:15:17] [INFO]: ===Rank-1 (Exclude identical-view cases)===\n[2025-10-01 18:15:17] [INFO]: NM@R1: [93.50 98.20 99.20 97.90 95.70 93.40 96.90 99.10 99.30 99.10 92.60]\n[2025-10-01 18:15:17] [INFO]: BG@R1: [90.70 95.80 96.60 94.65 92.60 87.50 91.10 96.00 98.40 96.87 87.90]\n[2025-10-01 18:15:17] [INFO]: CL@R1: [69.70 88.20 90.90 87.40 82.20 74.00 80.10 84.80 86.40 81.90 64.50]\n[2025-10-01 18:15:17] [INFO]: NM@R1: 96.81%\tBG@R1: 93.47%\tCL@R1: 80.92%\t\n[rank0]:[W1001 18:15:18.089015780 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import os\n\ndef print_tree(startpath):\n    for root, dirs, files in os.walk(startpath):\n        level = root.replace(startpath, '').count(os.sep)\n        indent = '│   ' * level + '├── '\n        print(f\"{indent}{os.path.basename(root)}/\")\n        subindent = '│   ' * (level + 1) + '├── '\n        for f in files:\n            print(f\"{subindent}{f}\")\n\nprint_tree('/kaggle/working/OpenGait/output/CASIA-B/GaitGL/GaitGL/checkpoints/GaitGL-80000.pt')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:16:29.491466Z","iopub.execute_input":"2025-10-01T18:16:29.491770Z","iopub.status.idle":"2025-10-01T18:16:29.498040Z","shell.execute_reply.started":"2025-10-01T18:16:29.491727Z","shell.execute_reply":"2025-10-01T18:16:29.497458Z"}},"outputs":[{"name":"stdout","text":"├── /\n├── GaitGL/\n│   ├── summary/\n│   │   ├── events.out.tfevents.1759068014.1a0949e6b7b1.237.0\n│   │   ├── events.out.tfevents.1759067821.1a0949e6b7b1.198.0\n│   │   ├── events.out.tfevents.1759326004.fd0f06dcee30.87.0\n│   │   ├── events.out.tfevents.1759280164.c67e4998cba5.80.0\n│   ├── checkpoints/\n│   │   ├── GaitGL-60000.pt\n│   │   ├── GaitGL-70000.pt\n│   │   ├── GaitGL-10000.pt\n│   │   ├── GaitGL-30000.pt\n│   │   ├── GaitGL-80000.pt\n│   │   ├── GaitGL-50000.pt\n│   │   ├── GaitGL-40000.pt\n│   │   ├── GaitGL-20000.pt\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"# Analyze GAIT GL Model","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport pickle\nimport json\nimport time\nfrom collections import OrderedDict\nimport sys\n\n\ndef analyze_gait_model(model_path, config_path=None, test_data_path=None, device='cuda'):\n    \"\"\"\n    Comprehensive analysis of gait model with detailed metrics table.\n    \n    Args:\n        model_path (str): Path to the saved model checkpoint\n        config_path (str, optional): Path to the YAML config file\n        test_data_path (str, optional): Path to test dataset for accuracy evaluation\n        device (str): Device to load model on\n    \n    Returns:\n        pd.DataFrame: Detailed analysis table\n    \"\"\"\n    \n    print(\"🔍 Starting comprehensive gait model analysis...\")\n    \n    # Initialize results dictionary\n    analysis_results = OrderedDict()\n    \n    # =========================\n    # 1. BASIC MODEL INFO\n    # =========================\n    print(\"📊 Analyzing basic model information...\")\n    \n    try:\n        # Load checkpoint\n        checkpoint = torch.load(model_path, map_location=device)\n        \n        # Extract model information\n        analysis_results['Model Path'] = model_path\n        analysis_results['Checkpoint Keys'] = list(checkpoint.keys())\n        \n        if 'iteration' in checkpoint:\n            analysis_results['Training Iteration'] = checkpoint['iteration']\n        \n        if 'model' in checkpoint:\n            model_state = checkpoint['model']\n        elif 'model_state_dict' in checkpoint:\n            model_state = checkpoint['model_state_dict']\n        else:\n            model_state = checkpoint\n            \n    except Exception as e:\n        print(f\"❌ Error loading model: {e}\")\n        return pd.DataFrame()\n    \n    # =========================\n    # 2. PARAMETER ANALYSIS\n    # =========================\n    print(\"🔢 Analyzing model parameters...\")\n    \n    def analyze_parameters(state_dict):\n        total_params = 0\n        trainable_params = 0\n        layer_info = {}\n        \n        for name, param in state_dict.items():\n            if isinstance(param, torch.Tensor):\n                param_count = param.numel()\n                total_params += param_count\n                trainable_params += param_count  # Assume all loaded params are trainable\n                \n                # Categorize layers\n                if 'conv' in name.lower():\n                    layer_info['Conv Layers'] = layer_info.get('Conv Layers', 0) + param_count\n                elif 'bn' in name.lower() or 'batchnorm' in name.lower():\n                    layer_info['BatchNorm Layers'] = layer_info.get('BatchNorm Layers', 0) + param_count\n                elif 'fc' in name.lower() or 'linear' in name.lower():\n                    layer_info['Linear Layers'] = layer_info.get('Linear Layers', 0) + param_count\n                elif 'embed' in name.lower():\n                    layer_info['Embedding Layers'] = layer_info.get('Embedding Layers', 0) + param_count\n                else:\n                    layer_info['Other Layers'] = layer_info.get('Other Layers', 0) + param_count\n        \n        return total_params, trainable_params, layer_info\n    \n    total_params, trainable_params, layer_breakdown = analyze_parameters(model_state)\n    \n    analysis_results['Total Parameters'] = f\"{total_params:,}\"\n    analysis_results['Trainable Parameters'] = f\"{trainable_params:,}\"\n    analysis_results['Model Size (MB)'] = f\"{total_params * 4 / (1024**2):.2f}\"  # Assuming float32\n    \n    # Add layer breakdown\n    for layer_type, param_count in layer_breakdown.items():\n        analysis_results[f'{layer_type} Parameters'] = f\"{param_count:,}\"\n    \n    # =========================\n    # 3. MODEL ARCHITECTURE ANALYSIS\n    # =========================\n    print(\"🏗️ Analyzing model architecture...\")\n    \n    try:\n        # Try to load config if provided\n        if config_path and os.path.exists(config_path):\n            import yaml\n            with open(config_path, 'r') as f:\n                config = yaml.safe_load(f)\n            \n            analysis_results['Model Type'] = config.get('model_cfg', {}).get('model', 'Unknown')\n            analysis_results['Backbone'] = config.get('model_cfg', {}).get('backbone_cfg', {}).get('type', 'Unknown')\n            analysis_results['Dataset'] = config.get('data_cfg', {}).get('dataset_name', 'Unknown')\n            \n            # Training configuration\n            analysis_results['Learning Rate'] = config.get('optimizer_cfg', {}).get('lr', 'Unknown')\n            analysis_results['Batch Size'] = config.get('trainer_cfg', {}).get('sampler', {}).get('batch_size', 'Unknown')\n            analysis_results['Total Iterations'] = config.get('trainer_cfg', {}).get('total_iter', 'Unknown')\n            \n    except Exception as e:\n        print(f\"⚠️ Could not load config: {e}\")\n    \n    # Analyze layer structure from state dict\n    layer_names = list(model_state.keys())\n    analysis_results['Total Layers'] = len(layer_names)\n    \n    # Count different layer types\n    conv_layers = len([name for name in layer_names if 'conv' in name.lower() and 'weight' in name])\n    bn_layers = len([name for name in layer_names if ('bn' in name.lower() or 'batchnorm' in name.lower()) and 'weight' in name])\n    fc_layers = len([name for name in layer_names if ('fc' in name.lower() or 'linear' in name.lower()) and 'weight' in name])\n    \n    analysis_results['Conv Layers Count'] = conv_layers\n    analysis_results['BatchNorm Layers Count'] = bn_layers\n    analysis_results['Linear Layers Count'] = fc_layers\n    \n    # =========================\n    # 4. MEMORY ANALYSIS\n    # =========================\n    print(\"💾 Analyzing memory requirements...\")\n    \n    # Calculate memory footprint\n    param_memory = sum(param.numel() * param.element_size() for param in model_state.values() if isinstance(param, torch.Tensor))\n    analysis_results['Parameter Memory (MB)'] = f\"{param_memory / (1024**2):.2f}\"\n    \n    # Estimate activation memory (rough estimate for typical gait input)\n    # Assuming input size: (batch=8, frames=30, channels=1, height=64, width=44)\n    estimated_activation_memory = 8 * 30 * 1 * 64 * 44 * 4  # 4 bytes per float32\n    analysis_results['Estimated Activation Memory (MB)'] = f\"{estimated_activation_memory / (1024**2):.2f}\"\n    \n    # =========================\n    # 5. PERFORMANCE METRICS\n    # =========================\n    print(\"⚡ Analyzing performance characteristics...\")\n    \n    # Try to estimate FLOPs (simplified)\n    def estimate_flops(state_dict):\n        total_flops = 0\n        for name, param in state_dict.items():\n            if 'conv' in name.lower() and 'weight' in name:\n                # Rough FLOP estimation for conv layers\n                if param.dim() == 4:  # Conv2D\n                    out_channels, in_channels, kh, kw = param.shape\n                    # Assuming typical gait input resolution\n                    total_flops += out_channels * in_channels * kh * kw * 64 * 44  # Rough estimate\n            elif ('fc' in name.lower() or 'linear' in name.lower()) and 'weight' in name:\n                # FLOP estimation for linear layers\n                if param.dim() == 2:\n                    total_flops += param.shape[0] * param.shape[1]\n        return total_flops\n    \n    estimated_flops = estimate_flops(model_state)\n    analysis_results['Estimated FLOPs'] = f\"{estimated_flops:,}\"\n    analysis_results['Estimated GFLOPs'] = f\"{estimated_flops / (10**9):.2f}\"\n    \n    # =========================\n    # 6. FILE ANALYSIS\n    # =========================\n    print(\"📁 Analyzing checkpoint file...\")\n    \n    file_size = os.path.getsize(model_path)\n    analysis_results['Checkpoint Size (MB)'] = f\"{file_size / (1024**2):.2f}\"\n    analysis_results['File Extension'] = Path(model_path).suffix\n    \n    # Check compression ratio\n    try:\n        import gzip\n        with open(model_path, 'rb') as f:\n            original_size = len(f.read())\n        \n        compressed_size = len(gzip.compress(open(model_path, 'rb').read()))\n        compression_ratio = compressed_size / original_size\n        analysis_results['Compression Ratio'] = f\"{compression_ratio:.3f}\"\n    except:\n        analysis_results['Compression Ratio'] = \"N/A\"\n    \n    # =========================\n    # 7. LAYER DISTRIBUTION ANALYSIS\n    # =========================\n    print(\"📊 Analyzing layer distribution...\")\n    \n    # Analyze parameter distribution across layers\n    layer_sizes = {}\n    for name, param in model_state.items():\n        if isinstance(param, torch.Tensor) and 'weight' in name:\n            layer_name = name.replace('.weight', '')\n            layer_sizes[layer_name] = param.numel()\n    \n    if layer_sizes:\n        # Find largest and smallest layers\n        largest_layer = max(layer_sizes, key=layer_sizes.get)\n        smallest_layer = min(layer_sizes, key=layer_sizes.get)\n        \n        analysis_results['Largest Layer'] = f\"{largest_layer} ({layer_sizes[largest_layer]:,} params)\"\n        analysis_results['Smallest Layer'] = f\"{smallest_layer} ({layer_sizes[smallest_layer]:,} params)\"\n        analysis_results['Avg Layer Size'] = f\"{np.mean(list(layer_sizes.values())):.0f}\"\n    \n    # =========================\n    # 8. TRAINING INFORMATION\n    # =========================\n    print(\"🎯 Extracting training information...\")\n    \n    if 'optimizer' in checkpoint:\n        analysis_results['Optimizer State Available'] = \"Yes\"\n    else:\n        analysis_results['Optimizer State Available'] = \"No\"\n    \n    if 'scheduler' in checkpoint:\n        analysis_results['Scheduler State Available'] = \"Yes\"\n    else:\n        analysis_results['Scheduler State Available'] = \"No\"\n    \n    # Extract any loss information\n    if 'loss' in checkpoint:\n        analysis_results['Final Loss'] = f\"{checkpoint['loss']:.6f}\"\n    \n    # =========================\n    # 9. COMPATIBILITY ANALYSIS\n    # =========================\n    print(\"🔧 Analyzing compatibility...\")\n    \n    analysis_results['PyTorch Version Compatible'] = f\"PyTorch {torch.__version__}\"\n    analysis_results['CUDA Available'] = torch.cuda.is_available()\n    \n    if torch.cuda.is_available():\n        analysis_results['CUDA Version'] = torch.version.cuda\n        analysis_results['GPU Count'] = torch.cuda.device_count()\n    \n    # =========================\n    # 10. CREATE SUMMARY TABLE\n    # =========================\n    print(\"📋 Creating summary table...\")\n    \n    # Convert to DataFrame for nice display\n    df = pd.DataFrame.from_dict(analysis_results, orient='index', columns=['Value'])\n    df.index.name = 'Metric'\n    \n    # Add categories for better organization\n    categories = []\n    for metric in df.index:\n        if metric in ['Model Path', 'Model Type', 'Backbone', 'Dataset']:\n            categories.append('Basic Info')\n        elif 'Parameters' in metric or 'Size' in metric:\n            categories.append('Architecture')\n        elif 'Memory' in metric or 'FLOP' in metric:\n            categories.append('Performance')\n        elif 'Layer' in metric:\n            categories.append('Structure')\n        elif any(word in metric for word in ['Iteration', 'Loss', 'Learning', 'Batch', 'Optimizer']):\n            categories.append('Training')\n        elif any(word in metric for word in ['File', 'Checkpoint', 'Compression']):\n            categories.append('Storage')\n        else:\n            categories.append('Other')\n    \n    df['Category'] = categories\n    \n    # Reorder columns\n    df = df[['Category', 'Value']]\n    \n    print(\"✅ Analysis complete!\")\n    \n    return df\n\ndef save_analysis_table(df, output_path=\"model_analysis.csv\", format_type=\"csv\"):\n    \"\"\"Save the analysis table in various formats\"\"\"\n    \n    if format_type.lower() == \"csv\":\n        df.to_csv(output_path)\n    elif format_type.lower() == \"excel\":\n        df.to_excel(output_path.replace('.csv', '.xlsx'))\n    elif format_type.lower() == \"html\":\n        df.to_html(output_path.replace('.csv', '.html'))\n    \n    print(f\"💾 Analysis saved to {output_path}\")\n\ndef display_analysis(df, group_by_category=True):\n    \"\"\"Display the analysis table in a formatted way\"\"\"\n    \n    print(\"=\" * 80)\n    print(\"🚀 GAIT MODEL ANALYSIS REPORT\")\n    print(\"=\" * 80)\n    \n    if group_by_category:\n        # Group by category for better readability\n        for category in df['Category'].unique():\n            print(f\"\\n📊 {category.upper()}\")\n            print(\"-\" * 40)\n            category_df = df[df['Category'] == category]\n            for metric, row in category_df.iterrows():\n                print(f\"{metric:<30}: {row['Value']}\")\n    else:\n        # Display all at once\n        for metric, row in df.iterrows():\n            print(f\"{metric:<30}: {row['Value']}\")\n    \n    print(\"=\" * 80)\n\n\n\ndef analyze_my_gait_model():\n    ''' # Usage '''\n    # Define paths \n    model_path = \"/kaggle/working/geta_gaitGL/OpenGait/output/CASIA-B/GaitGLGeta/GaitGL_GETA/checkpoints/GaitGL_GETA-80000.pt\"\n    config_path = \"/kaggle/working/geta_gaitGL/OpenGait/configs/gaitgl/gaitgl_geta.yaml\"\n    \n    # Check if model exists\n    if not os.path.exists(model_path):\n        print(\"❌ Model checkpoint not found!\")\n        print(\"Available checkpoints:\")\n        checkpoint_dir = \"/kaggle/working/geta_gaitGL/OpenGait/output/CASIA-B/GaitGLGeta/GaitGL_GETA/checkpoints/\"\n        if os.path.exists(checkpoint_dir):\n            for file in os.listdir(checkpoint_dir):\n                if file.endswith('.pt'):\n                    print(f\"  📁 {file}\")\n        return None\n    \n    # Run analysis\n    analysis_df = analyze_gait_model(\n        model_path=model_path,\n        config_path=config_path,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n\n    \n    \n    # Display results\n    display_analysis(analysis_df)\n    \n    # Save results\n    save_analysis_table(analysis_df, \"geta_gait_analysis-1.csv\")\n    save_analysis_table(analysis_df, \"geta_gait_analysis-1.xlsx\", \"excel\")\n    \n    return analysis_df\n\n\n# Run the analysis\nif __name__ == \"__main__\":\n    df = analyze_my_gait_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:47:17.178475Z","iopub.execute_input":"2025-09-28T13:47:17.179307Z","iopub.status.idle":"2025-09-28T13:47:20.767216Z","shell.execute_reply.started":"2025-09-28T13:47:17.179261Z","shell.execute_reply":"2025-09-28T13:47:20.766450Z"}},"outputs":[{"name":"stdout","text":"🔍 Starting comprehensive gait model analysis...\n📊 Analyzing basic model information...\n🔢 Analyzing model parameters...\n🏗️ Analyzing model architecture...\n💾 Analyzing memory requirements...\n⚡ Analyzing performance characteristics...\n📁 Analyzing checkpoint file...\n📊 Analyzing layer distribution...\n🎯 Extracting training information...\n🔧 Analyzing compatibility...\n📋 Creating summary table...\n✅ Analysis complete!\n================================================================================\n🚀 GAIT MODEL ANALYSIS REPORT\n================================================================================\n\n📊 BASIC INFO\n----------------------------------------\nModel Path                    : /kaggle/working/geta_gaitGL/OpenGait/output/CASIA-B/GaitGLGeta/GaitGL_GETA/checkpoints/GaitGL_GETA-80000.pt\nModel Type                    : GaitGLGeta\nBackbone                      : Unknown\nDataset                       : CASIA-B\n\n📊 STORAGE\n----------------------------------------\nCheckpoint Keys               : ['model', 'optimizer', 'scheduler', 'iteration']\nFile Extension                : .pt\nCompression Ratio             : 0.935\n\n📊 TRAINING\n----------------------------------------\nTraining Iteration            : 80000\nLearning Rate                 : Unknown\nTotal Iterations              : 80000\nOptimizer State Available     : Yes\n\n📊 ARCHITECTURE\n----------------------------------------\nTotal Parameters              : 3,096,930\nTrainable Parameters          : 3,096,930\nModel Size (MB)               : 11.81\nConv Layers Parameters        : 1,441,632\nOther Layers Parameters       : 1\nLinear Layers Parameters      : 1,654,784\nBatchNorm Layers Parameters   : 513\nBatch Size                    : [8, 8]\nCheckpoint Size (MB)          : 11.82\nAvg Layer Size                : 160196\n\n📊 STRUCTURE\n----------------------------------------\nTotal Layers                  : 16\nConv Layers Count             : 8\nBatchNorm Layers Count        : 1\nLinear Layers Count           : 0\nLargest Layer                 : GLConvB2.global_conv3d.conv3d (442,368 params)\nSmallest Layer                : Bn (128 params)\n\n📊 PERFORMANCE\n----------------------------------------\nParameter Memory (MB)         : 11.81\nEstimated Activation Memory (MB): 2.58\nEstimated FLOPs               : 0\nEstimated GFLOPs              : 0.00\n\n📊 OTHER\n----------------------------------------\nScheduler State Available     : Yes\nPyTorch Version Compatible    : PyTorch 2.6.0+cu124\nCUDA Available                : True\nCUDA Version                  : 12.4\nGPU Count                     : 2\n================================================================================\n💾 Analysis saved to geta_gait_analysis-1.csv\n💾 Analysis saved to geta_gait_analysis-1.xlsx\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport pickle\nimport json\nimport time\nfrom collections import OrderedDict\nimport sys\n\n\ndef analyze_gait_model(model_path, config_path=None, test_data_path=None, device='cuda'):\n    \"\"\"\n    Comprehensive analysis of gait model with detailed metrics table.\n    \n    Args:\n        model_path (str): Path to the saved model checkpoint\n        config_path (str, optional): Path to the YAML config file\n        test_data_path (str, optional): Path to test dataset for accuracy evaluation\n        device (str): Device to load model on\n    \n    Returns:\n        pd.DataFrame: Detailed analysis table\n    \"\"\"\n    \n    print(\"🔍 Starting comprehensive gait model analysis...\")\n    \n    # Initialize results dictionary\n    analysis_results = OrderedDict()\n    \n    # =========================\n    # 1. BASIC MODEL INFO\n    # =========================\n    print(\"📊 Analyzing basic model information...\")\n    \n    try:\n        # Load checkpoint\n        checkpoint = torch.load(model_path, map_location=device)\n        \n        # Extract model information\n        analysis_results['Model Path'] = model_path\n        analysis_results['Checkpoint Keys'] = list(checkpoint.keys())\n        \n        if 'iteration' in checkpoint:\n            analysis_results['Training Iteration'] = checkpoint['iteration']\n        \n        if 'model' in checkpoint:\n            model_state = checkpoint['model']\n        elif 'model_state_dict' in checkpoint:\n            model_state = checkpoint['model_state_dict']\n        else:\n            model_state = checkpoint\n            \n    except Exception as e:\n        print(f\"❌ Error loading model: {e}\")\n        return pd.DataFrame()\n    \n    # =========================\n    # 2. PARAMETER ANALYSIS\n    # =========================\n    print(\"🔢 Analyzing model parameters...\")\n    \n    def analyze_parameters(state_dict):\n        total_params = 0\n        trainable_params = 0\n        layer_info = {}\n        \n        for name, param in state_dict.items():\n            if isinstance(param, torch.Tensor):\n                param_count = param.numel()\n                total_params += param_count\n                trainable_params += param_count  # Assume all loaded params are trainable\n                \n                # Categorize layers\n                if 'conv' in name.lower():\n                    layer_info['Conv Layers'] = layer_info.get('Conv Layers', 0) + param_count\n                elif 'bn' in name.lower() or 'batchnorm' in name.lower():\n                    layer_info['BatchNorm Layers'] = layer_info.get('BatchNorm Layers', 0) + param_count\n                elif 'fc' in name.lower() or 'linear' in name.lower():\n                    layer_info['Linear Layers'] = layer_info.get('Linear Layers', 0) + param_count\n                elif 'embed' in name.lower():\n                    layer_info['Embedding Layers'] = layer_info.get('Embedding Layers', 0) + param_count\n                else:\n                    layer_info['Other Layers'] = layer_info.get('Other Layers', 0) + param_count\n        \n        return total_params, trainable_params, layer_info\n    \n    total_params, trainable_params, layer_breakdown = analyze_parameters(model_state)\n    \n    analysis_results['Total Parameters'] = f\"{total_params:,}\"\n    analysis_results['Trainable Parameters'] = f\"{trainable_params:,}\"\n    analysis_results['Model Size (MB)'] = f\"{total_params * 4 / (1024**2):.2f}\"  # Assuming float32\n    \n    # Add layer breakdown\n    for layer_type, param_count in layer_breakdown.items():\n        analysis_results[f'{layer_type} Parameters'] = f\"{param_count:,}\"\n    \n    # =========================\n    # 3. MODEL ARCHITECTURE ANALYSIS\n    # =========================\n    print(\"🏗️ Analyzing model architecture...\")\n    \n    try:\n        # Try to load config if provided\n        if config_path and os.path.exists(config_path):\n            import yaml\n            with open(config_path, 'r') as f:\n                config = yaml.safe_load(f)\n            \n            analysis_results['Model Type'] = config.get('model_cfg', {}).get('model', 'Unknown')\n            analysis_results['Backbone'] = config.get('model_cfg', {}).get('backbone_cfg', {}).get('type', 'Unknown')\n            analysis_results['Dataset'] = config.get('data_cfg', {}).get('dataset_name', 'Unknown')\n            \n            # Training configuration\n            analysis_results['Learning Rate'] = config.get('optimizer_cfg', {}).get('lr', 'Unknown')\n            analysis_results['Batch Size'] = config.get('trainer_cfg', {}).get('sampler', {}).get('batch_size', 'Unknown')\n            analysis_results['Total Iterations'] = config.get('trainer_cfg', {}).get('total_iter', 'Unknown')\n            \n    except Exception as e:\n        print(f\"⚠️ Could not load config: {e}\")\n    \n    # Analyze layer structure from state dict\n    layer_names = list(model_state.keys())\n    analysis_results['Total Layers'] = len(layer_names)\n    \n    # Count different layer types\n    conv_layers = len([name for name in layer_names if 'conv' in name.lower() and 'weight' in name])\n    bn_layers = len([name for name in layer_names if ('bn' in name.lower() or 'batchnorm' in name.lower()) and 'weight' in name])\n    fc_layers = len([name for name in layer_names if ('fc' in name.lower() or 'linear' in name.lower()) and 'weight' in name])\n    \n    analysis_results['Conv Layers Count'] = conv_layers\n    analysis_results['BatchNorm Layers Count'] = bn_layers\n    analysis_results['Linear Layers Count'] = fc_layers\n    \n    # =========================\n    # 4. MEMORY ANALYSIS\n    # =========================\n    print(\"💾 Analyzing memory requirements...\")\n    \n    # Calculate memory footprint\n    param_memory = sum(param.numel() * param.element_size() for param in model_state.values() if isinstance(param, torch.Tensor))\n    analysis_results['Parameter Memory (MB)'] = f\"{param_memory / (1024**2):.2f}\"\n    \n    # Estimate activation memory (rough estimate for typical gait input)\n    # Assuming input size: (batch=8, frames=30, channels=1, height=64, width=44)\n    estimated_activation_memory = 8 * 30 * 1 * 64 * 44 * 4  # 4 bytes per float32\n    analysis_results['Estimated Activation Memory (MB)'] = f\"{estimated_activation_memory / (1024**2):.2f}\"\n    \n    # =========================\n    # 5. PERFORMANCE METRICS\n    # =========================\n    print(\"⚡ Analyzing performance characteristics...\")\n    \n    # Try to estimate FLOPs (simplified)\n    def estimate_flops(state_dict):\n        total_flops = 0\n        for name, param in state_dict.items():\n            if 'conv' in name.lower() and 'weight' in name:\n                # Rough FLOP estimation for conv layers\n                if param.dim() == 4:  # Conv2D\n                    out_channels, in_channels, kh, kw = param.shape\n                    # Assuming typical gait input resolution\n                    total_flops += out_channels * in_channels * kh * kw * 64 * 44  # Rough estimate\n            elif ('fc' in name.lower() or 'linear' in name.lower()) and 'weight' in name:\n                # FLOP estimation for linear layers\n                if param.dim() == 2:\n                    total_flops += param.shape[0] * param.shape[1]\n        return total_flops\n    \n    estimated_flops = estimate_flops(model_state)\n    analysis_results['Estimated FLOPs'] = f\"{estimated_flops:,}\"\n    analysis_results['Estimated GFLOPs'] = f\"{estimated_flops / (10**9):.2f}\"\n    \n    # =========================\n    # 6. FILE ANALYSIS\n    # =========================\n    print(\"📁 Analyzing checkpoint file...\")\n    \n    file_size = os.path.getsize(model_path)\n    analysis_results['Checkpoint Size (MB)'] = f\"{file_size / (1024**2):.2f}\"\n    analysis_results['File Extension'] = Path(model_path).suffix\n    \n    # Check compression ratio\n    try:\n        import gzip\n        with open(model_path, 'rb') as f:\n            original_size = len(f.read())\n        \n        compressed_size = len(gzip.compress(open(model_path, 'rb').read()))\n        compression_ratio = compressed_size / original_size\n        analysis_results['Compression Ratio'] = f\"{compression_ratio:.3f}\"\n    except:\n        analysis_results['Compression Ratio'] = \"N/A\"\n    \n    # =========================\n    # 7. LAYER DISTRIBUTION ANALYSIS\n    # =========================\n    print(\"📊 Analyzing layer distribution...\")\n    \n    # Analyze parameter distribution across layers\n    layer_sizes = {}\n    for name, param in model_state.items():\n        if isinstance(param, torch.Tensor) and 'weight' in name:\n            layer_name = name.replace('.weight', '')\n            layer_sizes[layer_name] = param.numel()\n    \n    if layer_sizes:\n        # Find largest and smallest layers\n        largest_layer = max(layer_sizes, key=layer_sizes.get)\n        smallest_layer = min(layer_sizes, key=layer_sizes.get)\n        \n        analysis_results['Largest Layer'] = f\"{largest_layer} ({layer_sizes[largest_layer]:,} params)\"\n        analysis_results['Smallest Layer'] = f\"{smallest_layer} ({layer_sizes[smallest_layer]:,} params)\"\n        analysis_results['Avg Layer Size'] = f\"{np.mean(list(layer_sizes.values())):.0f}\"\n    \n    # =========================\n    # 8. TRAINING INFORMATION\n    # =========================\n    print(\"🎯 Extracting training information...\")\n    \n    if 'optimizer' in checkpoint:\n        analysis_results['Optimizer State Available'] = \"Yes\"\n    else:\n        analysis_results['Optimizer State Available'] = \"No\"\n    \n    if 'scheduler' in checkpoint:\n        analysis_results['Scheduler State Available'] = \"Yes\"\n    else:\n        analysis_results['Scheduler State Available'] = \"No\"\n    \n    # Extract any loss information\n    if 'loss' in checkpoint:\n        analysis_results['Final Loss'] = f\"{checkpoint['loss']:.6f}\"\n    \n    # =========================\n    # 9. COMPATIBILITY ANALYSIS\n    # =========================\n    print(\"🔧 Analyzing compatibility...\")\n    \n    analysis_results['PyTorch Version Compatible'] = f\"PyTorch {torch.__version__}\"\n    analysis_results['CUDA Available'] = torch.cuda.is_available()\n    \n    if torch.cuda.is_available():\n        analysis_results['CUDA Version'] = torch.version.cuda\n        analysis_results['GPU Count'] = torch.cuda.device_count()\n    \n    # =========================\n    # 10. CREATE SUMMARY TABLE\n    # =========================\n    print(\"📋 Creating summary table...\")\n    \n    # Convert to DataFrame for nice display\n    df = pd.DataFrame.from_dict(analysis_results, orient='index', columns=['Value'])\n    df.index.name = 'Metric'\n    \n    # Add categories for better organization\n    categories = []\n    for metric in df.index:\n        if metric in ['Model Path', 'Model Type', 'Backbone', 'Dataset']:\n            categories.append('Basic Info')\n        elif 'Parameters' in metric or 'Size' in metric:\n            categories.append('Architecture')\n        elif 'Memory' in metric or 'FLOP' in metric:\n            categories.append('Performance')\n        elif 'Layer' in metric:\n            categories.append('Structure')\n        elif any(word in metric for word in ['Iteration', 'Loss', 'Learning', 'Batch', 'Optimizer']):\n            categories.append('Training')\n        elif any(word in metric for word in ['File', 'Checkpoint', 'Compression']):\n            categories.append('Storage')\n        else:\n            categories.append('Other')\n    \n    df['Category'] = categories\n    \n    # Reorder columns\n    df = df[['Category', 'Value']]\n    \n    print(\"✅ Analysis complete!\")\n    \n    return df\n\ndef save_analysis_table(df, output_path=\"model_analysis.csv\", format_type=\"csv\"):\n    \"\"\"Save the analysis table in various formats\"\"\"\n    \n    if format_type.lower() == \"csv\":\n        df.to_csv(output_path)\n    elif format_type.lower() == \"excel\":\n        df.to_excel(output_path.replace('.csv', '.xlsx'))\n    elif format_type.lower() == \"html\":\n        df.to_html(output_path.replace('.csv', '.html'))\n    \n    print(f\"💾 Analysis saved to {output_path}\")\n\ndef display_analysis(df, group_by_category=True):\n    \"\"\"Display the analysis table in a formatted way\"\"\"\n    \n    print(\"=\" * 80)\n    print(\"🚀 GAIT MODEL ANALYSIS REPORT\")\n    print(\"=\" * 80)\n    \n    if group_by_category:\n        # Group by category for better readability\n        for category in df['Category'].unique():\n            print(f\"\\n📊 {category.upper()}\")\n            print(\"-\" * 40)\n            category_df = df[df['Category'] == category]\n            for metric, row in category_df.iterrows():\n                print(f\"{metric:<30}: {row['Value']}\")\n    else:\n        # Display all at once\n        for metric, row in df.iterrows():\n            print(f\"{metric:<30}: {row['Value']}\")\n    \n    print(\"=\" * 80)\n\n\n\ndef analyze_my_gait_model():\n    ''' # Usage '''\n    # Define paths \n    model_path = \"/kaggle/working/OpenGait/output/CASIA-B/GaitGL/GaitGL/checkpoints/GaitGL-80000.pt\"\n    config_path = \"/kaggle/working/OpenGait/configs/gaitgl/gaitgl.yaml\"\n    \n    # Check if model exists\n    if not os.path.exists(model_path):\n        print(\"❌ Model checkpoint not found!\")\n        print(\"Available checkpoints:\")\n        checkpoint_dir = \"/kaggle/working/OpenGait/output/CASIA-B/GaitGL/GaitGL/checkpoints/\"\n        if os.path.exists(checkpoint_dir):\n            for file in os.listdir(checkpoint_dir):\n                if file.endswith('.pt'):\n                    print(f\"  📁 {file}\")\n        return None\n    \n    # Run analysis\n    analysis_df = analyze_gait_model(\n        model_path=model_path,\n        config_path=config_path,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    )\n\n    \n    \n    # Display results\n    display_analysis(analysis_df)\n    \n    # Save results\n    save_analysis_table(analysis_df, \"original_gaitGL_analysis-1.csv\")\n    save_analysis_table(analysis_df, \"original_gaitGL_-1.xlsx\", \"excel\")\n    \n    return analysis_df\n\n\n# Run the analysis\nif __name__ == \"__main__\":\n    df = analyze_my_gait_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T18:21:33.312834Z","iopub.execute_input":"2025-10-01T18:21:33.313464Z","iopub.status.idle":"2025-10-01T18:21:37.944104Z","shell.execute_reply.started":"2025-10-01T18:21:33.313442Z","shell.execute_reply":"2025-10-01T18:21:37.943498Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"🔍 Starting comprehensive gait model analysis...\n📊 Analyzing basic model information...\n🔢 Analyzing model parameters...\n🏗️ Analyzing model architecture...\n💾 Analyzing memory requirements...\n⚡ Analyzing performance characteristics...\n📁 Analyzing checkpoint file...\n📊 Analyzing layer distribution...\n🎯 Extracting training information...\n🔧 Analyzing compatibility...\n📋 Creating summary table...\n✅ Analysis complete!\n================================================================================\n🚀 GAIT MODEL ANALYSIS REPORT\n================================================================================\n\n📊 BASIC INFO\n----------------------------------------\nModel Path                    : /kaggle/working/OpenGait/output/CASIA-B/GaitGL/GaitGL/checkpoints/GaitGL-80000.pt\nModel Type                    : GaitGL\nBackbone                      : Unknown\nDataset                       : CASIA-B\n\n📊 STORAGE\n----------------------------------------\nCheckpoint Keys               : ['model', 'optimizer', 'scheduler', 'iteration']\nFile Extension                : .pt\nCompression Ratio             : 0.916\n\n📊 TRAINING\n----------------------------------------\nTraining Iteration            : 80000\nLearning Rate                 : 0.0001\nTotal Iterations              : 80000\nOptimizer State Available     : Yes\n\n📊 ARCHITECTURE\n----------------------------------------\nTotal Parameters              : 3,096,930\nTrainable Parameters          : 3,096,930\nModel Size (MB)               : 11.81\nConv Layers Parameters        : 1,441,632\nOther Layers Parameters       : 1\nLinear Layers Parameters      : 1,654,784\nBatchNorm Layers Parameters   : 513\nBatch Size                    : [8, 8]\nCheckpoint Size (MB)          : 35.46\nAvg Layer Size                : 160196\n\n📊 STRUCTURE\n----------------------------------------\nTotal Layers                  : 16\nConv Layers Count             : 8\nBatchNorm Layers Count        : 1\nLinear Layers Count           : 0\nLargest Layer                 : GLConvB2.global_conv3d.conv3d (442,368 params)\nSmallest Layer                : Bn (128 params)\n\n📊 PERFORMANCE\n----------------------------------------\nParameter Memory (MB)         : 11.81\nEstimated Activation Memory (MB): 2.58\nEstimated FLOPs               : 0\nEstimated GFLOPs              : 0.00\n\n📊 OTHER\n----------------------------------------\nScheduler State Available     : Yes\nPyTorch Version Compatible    : PyTorch 2.6.0+cu124\nCUDA Available                : True\nCUDA Version                  : 12.4\nGPU Count                     : 2\n================================================================================\n💾 Analysis saved to original_gaitGL_analysis-1.csv\n💾 Analysis saved to original_gaitGL_-1.xlsx\n","output_type":"stream"}],"execution_count":63}]}